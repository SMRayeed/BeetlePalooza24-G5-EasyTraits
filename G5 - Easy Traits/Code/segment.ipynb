{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2684df5-0a8c-4c6d-af81-02c02eda5524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ac6b680-fe20-4b69-b10e-cf525d9c9385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device:  cuda:0\n",
      "__CUDNN VERSION: 90100\n",
      "__Number CUDA Devices: 1\n",
      "__CUDA Device Name: GRID A100X-40C\n",
      "__CUDA Device Total Memory [GB]: 42.945347584\n",
      "Number of images in dataset: 0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'sam' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# load SAM model\u001b[39;00m\n\u001b[1;32m     45\u001b[0m segmentation_model \u001b[38;5;241m=\u001b[39m get_sam_model(DEVICE) \u001b[38;5;66;03m#set of weight sthat you load into the model - someone else have already wrote it down\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m segmentation_model \u001b[38;5;241m=\u001b[39m SamPredictor(\u001b[43msam\u001b[49m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m#preparing for a loop to apply the SAM model to all the images)\u001b[39;00m\n\u001b[1;32m     50\u001b[0m i \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;66;03m#df indexer\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sam' is not defined"
     ]
    }
   ],
   "source": [
    "# applying the first mask segmentation to the four pictures\n",
    "\n",
    "# importing packages\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# running another code already done and saved\n",
    "sys.path.append(\"./2018-NEON-beetles-processing/segmentation\") \n",
    "from predict_masks import *\n",
    "\n",
    "\n",
    "# the two layers of the image\n",
    "classes = {0: 'background', 1: 'beetle'}\n",
    "csv_annot = './data/BeetleMeasurements.csv'\n",
    "result_path = './data/seg_results.csv' #this is already telling how many beetles there is in the image\n",
    "\n",
    "# Leverage GPU if available\n",
    "use_cuda = torch.cuda.is_available()\n",
    "DEVICE   = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "print(\"Device: \", DEVICE)\n",
    "\n",
    "if use_cuda:\n",
    "    print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
    "    print('__Number CUDA Devices:', torch.cuda.device_count())\n",
    "    print('__CUDA Device Name:',torch.cuda.get_device_name(0))\n",
    "    print('__CUDA Device Total Memory [GB]:',torch.cuda.get_device_properties(0).total_memory/1e9)\n",
    "\n",
    "# read beetle msmt csv in -- load the csv file in the environment (the main dataset)\n",
    "beetle_measurements = pd.read_csv(csv_annot)\n",
    "# beetle_measurements = beetle_measurements.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "# read images in\n",
    "dataset_folder = './data/input/*'\n",
    "mask_folder = './data/mask/'\n",
    "result_folder = './data/result/'\n",
    "image_filepaths = read_image_paths(dataset_folder)\n",
    "print(f'Number of images in dataset: {len(image_filepaths)}')\n",
    "\n",
    "# establish df to store segmentation info\n",
    "dataset_segmented = pd.DataFrame(columns = ['image', 'num_beetles'])\n",
    "\n",
    "# load SAM model\n",
    "segmentation_model = get_sam_model(DEVICE) #set of weight sthat you load into the model - someone else have already wrote it down\n",
    "segmentation_model = SamPredictor(sam)\n",
    "\n",
    "\n",
    "#preparing for a loop to apply the SAM model to all the images)\n",
    "i = 0 #df indexer\n",
    "print(\"Segmenting beetle images...\")\n",
    "for fp in image_filepaths:\n",
    "    print(fp)\n",
    "\n",
    "    #create a mask where beetle pixels are 1s and everything else is 0s\n",
    "    mask, num_beetles = get_mask(fp, #image\n",
    "                                 segmentation_model, #which model to appply\n",
    "                                 beetle_measurements) \n",
    "    \n",
    "    #create the path to which the mask will be saved\n",
    "    mask_path = os.path.join(mask_folder, fp.split('/')[-1]) #replace extension and save mask as a png\n",
    "    \n",
    "    os.makedirs(mask_folder, exist_ok=True)\n",
    "    \n",
    "    #save mask with cv2 to preserve pixel categories\n",
    "    print(f\"Mask path:{mask_path}\")\n",
    "    cv2.imwrite(mask_path, mask)\n",
    "\n",
    "    #enter relevant segmentation data for the image in our dataframe\n",
    "    dataset_segmented.loc[i, 'image'] = fp.split('/')[-1]\n",
    "    dataset_segmented.loc[i, 'num_beetles'] = num_beetles\n",
    "\n",
    "    i += 1\n",
    "\n",
    "# Save csv containing information about segmentation masks per each image\n",
    "dataset_segmented.to_csv(result_path, index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f26123-9482-48b8-bb86-9fe969f86c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# second step: take out the black background\n",
    "\n",
    "from remove_background import *\n",
    "\n",
    "dataset_images, image_filepaths = load_dataset_images(dataset_folder, 1)\n",
    "main_folder_name = dataset_folder.split('/')[-1]\n",
    "\n",
    "#load in our masks\n",
    "mask_dataset_folder = mask_folder\n",
    "dataset_masks, mask_filepaths = load_dataset_images(mask_folder)\n",
    "\n",
    "errors = []\n",
    "for (image, mask), fp in zip(zip(dataset_images, dataset_masks), image_filepaths): \n",
    "    #remove background from color image and replace it with a WHITE background\n",
    "    img_removed_background = remove_background_color_based(image, mask) \n",
    "\n",
    "    #save the image with the removed background under its own folder\n",
    "    bck_img_path = os.path.join(result_folder, fp.split('/')[-1])\n",
    "    \n",
    "    fn = \"/\" + bck_img_path.split('/')[-1]\n",
    "    # background_folder = bck_img_path.replace(fn, \"\")\n",
    "    os.makedirs(result_folder, exist_ok=True)\n",
    "\n",
    "    #save the resized cropped wings to their path\n",
    "    try:\n",
    "        cv2.imwrite(bck_img_path, cv2.cvtColor(img_removed_background, cv2.COLOR_RGB2BGR))\n",
    "    except FileNotFoundError:\n",
    "        errors.append(bck_img_path)\n",
    "        \n",
    "print('The following images could encountered errors during background removal:', errors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a833e05-8836-4e4e-8131-3f1f9f31cbf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
